<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>policytree: Policy Learning via Doubly Robust Empirical Welfare Maximization over Trees — policytree-package • policytree</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



  
  <script src="../extra.js"></script>

<meta property="og:title" content="policytree: Policy Learning via Doubly Robust Empirical Welfare Maximization over Trees — policytree-package" />
<meta property="og:description" content="A package for learning optimal policies via doubly robust empirical welfare maximization over trees. This package implements the multi-action doubly robust approach of Zhou et al. (2018) in the case where we want to learn policies that belong to the class of depth k decision trees. Many practical policy applications require interpretable predictions. For example, a drug prescription guide that follows a simple 2-question Yes/No checklist can be encoded as a depth 2 decision tree (does the patient have a heart condition - etc.). policytree currently has support for estimating multi-action treatment effects with one vs. all grf, calculating statistics such as double robust scores (support for a subset of grf forest types) and fitting optimal policies with exact tree search.
Some helpful links for getting started:
The R package documentation contains usage examples and method references.
For community questions and answers around usage, see the GitHub issues page.

" />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">policytree</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/policytree.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../CHANGELOG.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/grf-labs/policytree">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>policytree: Policy Learning via Doubly Robust Empirical Welfare Maximization over Trees</h1>
    <small class="dont-index">Source: <a href='https://github.com/grf-labs/policytree/blob/master/R/policytree-package.R'><code>R/policytree-package.R</code></a></small>
    <div class="hidden name"><code>policytree-package.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>A package for learning optimal policies via doubly robust empirical welfare maximization over trees. This package implements the multi-action doubly robust approach of Zhou et al. (2018) in the case where we want to learn policies that belong to the class of depth <em>k</em> decision trees. Many practical policy applications require interpretable predictions. For example, a drug prescription guide that follows a simple 2-question Yes/No checklist can be encoded as a depth 2 decision tree (does the patient have a heart condition - etc.). <code>policytree</code> currently has support for estimating multi-action treatment effects with one vs. all <a href='https://github.com/grf-labs/grf'>grf</a>, calculating statistics such as double robust scores (support for a subset of <em>grf</em> forest types) and fitting optimal policies with exact tree search.</p>
<p>Some helpful links for getting started:</p><ul>
<li><p>The <a href='https://grf-labs.github.io/policytree/'>R package documentation</a> contains usage examples and method references.</p></li>
<li><p>For community questions and answers around usage, see the GitHub <a href='https://github.com/grf-labs/policytree/issues'>issues page</a>.</p></li>
</ul>

    </div>



    <h2 class="hasAnchor" id="see-also"><a class="anchor" href="#see-also"></a>See also</h2>

    <div class='dont-index'><p>Useful links:</p><ul>
<li><p><a href='https://github.com/grf-labs/policytree'>https://github.com/grf-labs/policytree</a></p></li>
</ul>

</div>
    <h2 class="hasAnchor" id="author"><a class="anchor" href="#author"></a>Author</h2>

    <p><strong>Maintainer</strong>: Erik Sverdrup <a href='mailto:erikcs@stanford.edu'>erikcs@stanford.edu</a></p>
<p>Authors:</p><ul>
<li><p>Zhengyuan Zhou</p></li>
<li><p>Susan Athey</p></li>
<li><p>Stefan Wager</p></li>
<li><p>Ayush Kanodia</p></li>
</ul>



    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># \donttest{</span>
<span class='co'># Multi-action treatment effect estimation</span>
<span class='kw'>n</span> <span class='op'>&lt;-</span> <span class='fl'>250</span>
<span class='kw'>p</span> <span class='op'>&lt;-</span> <span class='fl'>10</span>
<span class='kw'>X</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span>(<span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>rnorm</a></span>(<span class='kw'>n</span> <span class='op'>*</span> <span class='kw'>p</span>), <span class='kw'>n</span>, <span class='kw'>p</span>)
<span class='kw'>W</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"A"</span>, <span class='st'>"B"</span>, <span class='st'>"C"</span>), <span class='kw'>n</span>, replace = <span class='fl'>TRUE</span>)
<span class='kw'>Y</span> <span class='op'>&lt;-</span> <span class='kw'>X</span>[, <span class='fl'>1</span>] <span class='op'>+</span> <span class='kw'>X</span>[, <span class='fl'>2</span>] <span class='op'>*</span> (<span class='kw'>W</span> <span class='op'>==</span> <span class='st'>"B"</span>) <span class='op'>+</span> <span class='kw'>X</span>[, <span class='fl'>3</span>] <span class='op'>*</span> (<span class='kw'>W</span> <span class='op'>==</span> <span class='st'>"C"</span>) <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/stats/Uniform.html'>runif</a></span>(<span class='kw'>n</span>)
<span class='kw'>multi.forest</span> <span class='op'>&lt;-</span> <span class='fu'><a href='multi_causal_forest.html'>multi_causal_forest</a></span>(X = <span class='kw'>X</span>, Y = <span class='kw'>Y</span>, W = <span class='kw'>W</span>)

<span class='co'># tau.hats</span>
<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='kw'>multi.forest</span>)<span class='op'>$</span><span class='kw'>predictions</span>
</div><div class='output co'>#&gt;                 A            B            C
#&gt; 1    0.1435295880  0.208221124 -0.906861730
#&gt; 2   -0.0172739078  1.140138201 -1.151592263
#&gt; 3   -0.1975272560 -0.650266915  0.872097893
#&gt; 4   -0.0997803511  0.088638799  0.188553170
#&gt; 5   -0.0539922634  1.226665180 -1.120508191
#&gt; 6   -0.0555672511 -0.795877173  0.905655351
#&gt; 7    0.2603439740 -0.482715894 -0.923031729
#&gt; 8   -0.0520654173  0.456591669 -0.088462672
#&gt; 9   -0.2108741852  0.350483487  0.489490761
#&gt; 10   0.0397317980 -0.975033551  0.664657724
#&gt; 11  -0.1204573289  1.114305077 -1.089109074
#&gt; 12  -0.0442383949 -0.801341326  0.827793864
#&gt; 13  -0.3056291966  0.825624832  0.303818017
#&gt; 14   0.1065972293  0.022808268 -0.198984656
#&gt; 15   0.1760312139 -0.638221550  0.181369613
#&gt; 16  -0.1211035398 -0.133458352  0.363709187
#&gt; 17  -0.1337373885 -0.342362195  0.748541586
#&gt; 18  -0.1275578557  0.910175817 -0.036727441
#&gt; 19  -0.1296566896 -0.121639142  0.549902440
#&gt; 20   0.0542267642  1.022521293 -1.233438836
#&gt; 21  -0.0228454727  1.216658289 -1.247971962
#&gt; 22   0.0606613031  0.002185174 -0.115878774
#&gt; 23   0.1482793399 -0.283035352 -0.010460036
#&gt; 24   0.0602161063  0.252556238 -0.352490500
#&gt; 25   0.1159301854 -0.932818937  0.584289712
#&gt; 26  -0.1320293306 -0.196017168  0.451698823
#&gt; 27  -0.1822714759  1.009542666 -0.187311510
#&gt; 28  -0.2317008330  0.497782078  0.491270989
#&gt; 29   0.2322126027 -0.594072753  0.013640546
#&gt; 30   0.2368054240 -0.261684730 -0.739118888
#&gt; 31   0.1072759214  0.214812597 -0.821283663
#&gt; 32  -0.0178173899 -0.917017887  0.597194060
#&gt; 33   0.1631958317  0.468350717 -1.199882646
#&gt; 34  -0.0587232376  1.175838972 -1.205972521
#&gt; 35  -0.2282873808  0.915734239  0.119281452
#&gt; 36  -0.0069420437  0.938008201 -1.162416995
#&gt; 37   0.0777443743 -0.804888718  0.366797301
#&gt; 38   0.0929341331  0.359512269 -0.593833229
#&gt; 39   0.2411767559  0.152514519 -1.092191701
#&gt; 40   0.0665694337  0.300621402 -0.348400568
#&gt; 41   0.2175330910 -0.569789036 -0.650280051
#&gt; 42   0.0006981825 -0.107840377  0.257321097
#&gt; 43   0.1769692152  0.032702811 -0.908599740
#&gt; 44  -0.2326805487  0.888929856  0.148540072
#&gt; 45  -0.1622087827 -0.174386154  0.563780558
#&gt; 46   0.2021284973 -0.795197193  0.143833722
#&gt; 47   0.1997362309 -0.800036064  0.181270402
#&gt; 48  -0.1591617138  0.954849802 -0.036123037
#&gt; 49  -0.0391881633 -0.763831579  0.680027322
#&gt; 50  -0.0753048303 -0.368132785  0.518600369
#&gt; 51   0.0403717158 -0.069419396  0.080100751
#&gt; 52   0.2278179593 -0.366793481 -0.775384712
#&gt; 53  -0.1183278310  0.522673122  0.097884608
#&gt; 54   0.1162204182 -0.814214539  0.491406563
#&gt; 55   0.2025153404 -0.555512678  0.105282315
#&gt; 56  -0.1229557940 -0.174676741  0.457842423
#&gt; 57  -0.0374599517 -0.782791098  0.833848394
#&gt; 58  -0.1930676056  0.347197939  0.313277639
#&gt; 59  -0.0370944371 -0.385597379  0.489364291
#&gt; 60   0.2004325560 -0.789762100  0.187866422
#&gt; 61   0.1939834553 -0.527354934  0.023557662
#&gt; 62  -0.1193809554 -0.256703029  0.566999184
#&gt; 63  -0.1054799545  1.169198988 -1.053637838
#&gt; 64  -0.2627490686  1.013452581  0.297421759
#&gt; 65  -0.3284662371  0.889622845  0.419484776
#&gt; 66   0.1445717377 -0.277537195 -0.370099997
#&gt; 67  -0.0821117789 -0.754783027  0.831140627
#&gt; 68  -0.0878134369 -0.546895761  0.745445789
#&gt; 69  -0.0659916568 -0.608790782  0.761200658
#&gt; 70   0.1025222779  0.072143955 -0.254516742
#&gt; 71  -0.0021161326 -1.020530960  0.873262067
#&gt; 72  -0.0135277612 -0.230407175  0.383823466
#&gt; 73   0.0737442767 -0.146577314 -0.066322185
#&gt; 74   0.1231178277  0.552018603 -1.145650484
#&gt; 75   0.1184134905  0.392525169 -1.117299869
#&gt; 76   0.1124819041  0.361551352 -1.089929034
#&gt; 77  -0.1457509138 -0.607764638  0.805727667
#&gt; 78  -0.1191085235  0.039386169  0.255494898
#&gt; 79   0.0812815082  0.020269593 -0.196605010
#&gt; 80  -0.0061039887 -0.853677726  0.583191817
#&gt; 81   0.1994630251 -0.487504943  0.079922818
#&gt; 82   0.0439959844 -0.208999355  0.262957526
#&gt; 83  -0.2647114135  0.867363811  0.325199415
#&gt; 84  -0.0525198352 -0.567088323  0.712631402
#&gt; 85   0.1585099954 -0.338732943 -0.620376480
#&gt; 86  -0.1425310325 -0.209883621  0.506585271
#&gt; 87   0.2045587900 -0.768794771  0.095694644
#&gt; 88   0.0159411832 -0.050657658  0.078987654
#&gt; 89  -0.0229721972 -0.993400165  0.899346655
#&gt; 90  -0.0742847408  1.176429235 -1.196784683
#&gt; 91  -0.1516427988  0.086675536  0.344911302
#&gt; 92  -0.1788740947 -0.065010642  0.581464121
#&gt; 93   0.0615837586 -0.026196256 -0.064254952
#&gt; 94  -0.0790593380 -0.042427701  0.255758045
#&gt; 95  -0.0505911633 -0.964645976  0.845508223
#&gt; 96   0.1935156705 -0.019767479 -0.931969114
#&gt; 97  -0.2963657872  0.898618015  0.356073435
#&gt; 98  -0.2443035479  0.927036814  0.122269657
#&gt; 99  -0.0639852582  0.817451247 -0.351782352
#&gt; 100 -0.1043075271  0.027977669  0.237553245
#&gt; 101  0.1326523382  0.334039343 -1.016957092
#&gt; 102 -0.1491315091  1.025625449 -0.291139816
#&gt; 103  0.1064387083  0.450351268 -1.029579842
#&gt; 104 -0.0473409895 -0.853774755  0.848955530
#&gt; 105  0.2251331289 -0.518908896 -0.743309704
#&gt; 106 -0.1752600010  0.153087196  0.405780154
#&gt; 107  0.0622681753 -0.738415815  0.543448130
#&gt; 108 -0.0627463250  1.078571007 -0.716788397
#&gt; 109  0.0177368848 -0.055347387  0.091944745
#&gt; 110 -0.1616381825 -0.098503469  0.407968608
#&gt; 111 -0.0850669769 -0.574960889  0.659905965
#&gt; 112 -0.0068586931  1.039598136 -1.118531471
#&gt; 113  0.0268443334 -0.190331777  0.181842349
#&gt; 114  0.1187600705 -0.702423592  0.419360746
#&gt; 115 -0.0301285548  0.905124907 -0.427085085
#&gt; 116  0.1642845372 -0.072616066 -0.253753188
#&gt; 117 -0.2808589236  0.939512437  0.321256216
#&gt; 118 -0.0516967661 -0.930525310  0.809507746
#&gt; 119 -0.1229901288 -0.736767922  0.844317889
#&gt; 120  0.2408386426 -0.588877705 -0.607369001
#&gt; 121 -0.0868108137 -0.366673158  0.691988126
#&gt; 122  0.2494051126 -0.457738900 -0.750068988
#&gt; 123 -0.0472788464  1.012412245 -0.341552936
#&gt; 124 -0.0919911718  0.864298177 -0.391829095
#&gt; 125 -0.0560984990  1.209830951 -1.123966979
#&gt; 126 -0.2330099774  0.115877618  0.565747202
#&gt; 127  0.0766556629  0.745476270 -1.220218157
#&gt; 128 -0.0399384126 -0.986221572  0.699900007
#&gt; 129  0.0895039823  0.153655251 -0.308099958
#&gt; 130 -0.1381247357  0.850061742 -0.326384638
#&gt; 131  0.1952224442 -0.549444088  0.187366700
#&gt; 132  0.0190216935 -0.679715590  0.604869174
#&gt; 133  0.1307773115  0.092164122 -0.308638849
#&gt; 134 -0.0358457814  1.008847156 -1.175375090
#&gt; 135 -0.0500157286 -0.978401159  0.754485056
#&gt; 136 -0.0794009621  0.561553433 -0.158054079
#&gt; 137  0.2103526692  0.281929824 -1.057649610
#&gt; 138  0.2188282808 -0.593561646 -0.668481750
#&gt; 139  0.1460123699  0.171092653 -1.020725353
#&gt; 140  0.0984184035 -0.814475634  0.603125008
#&gt; 141 -0.0506848037  1.156432799 -1.196685540
#&gt; 142  0.1775053616 -0.369910227 -0.706453021
#&gt; 143 -0.0817958939 -0.783396824  0.854749408
#&gt; 144  0.0130303261  1.199865429 -1.239970073
#&gt; 145 -0.0055335763  1.167070102 -1.075514269
#&gt; 146 -0.0854813438 -0.783459679  0.891662973
#&gt; 147 -0.0204440899  1.150878360 -1.016328549
#&gt; 148  0.1918359115 -0.735351918  0.090989805
#&gt; 149 -0.1780573592 -0.073059251  0.363507543
#&gt; 150  0.2472914963 -0.353328779 -0.882036639
#&gt; 151 -0.0728504832 -0.202048721  0.420630461
#&gt; 152  0.1618773771 -0.142540882 -0.797778583
#&gt; 153  0.0013154879  1.117226280 -1.205530427
#&gt; 154  0.0282734877  0.601662561 -0.934522496
#&gt; 155  0.0571679555  0.538175361 -1.123496139
#&gt; 156  0.0245020202  0.104374642 -0.169905381
#&gt; 157  0.2022127816 -0.272012153 -0.788207270
#&gt; 158  0.1449182990 -0.918988621  0.469167724
#&gt; 159 -0.2266404676  0.624472920  0.373655783
#&gt; 160 -0.1060485616  0.925257385  0.027625119
#&gt; 161  0.0827562689  0.247453382 -0.936018411
#&gt; 162 -0.0616265261  1.225266249 -1.157133977
#&gt; 163  0.2338049438 -0.304301804 -0.552197386
#&gt; 164  0.1444071272  0.261296550 -0.931653813
#&gt; 165 -0.0710302168 -0.723313767  0.680151860
#&gt; 166  0.1159098045  0.390032381 -1.095247212
#&gt; 167 -0.0173488083  0.594963049 -0.262203077
#&gt; 168 -0.0193619233 -0.984386984  0.763005438
#&gt; 169  0.0643553828 -0.777861803  0.566191365
#&gt; 170 -0.1009035350 -0.602992157  0.823817651
#&gt; 171 -0.0395709050  1.000801619 -1.200488297
#&gt; 172  0.1495094708  0.091393544 -0.881199422
#&gt; 173  0.0164033204  1.148521554 -1.106485354
#&gt; 174 -0.0205466157 -1.002452750  0.682431296
#&gt; 175 -0.1279409991  0.267165094  0.217513920
#&gt; 176  0.1630054863 -0.766071620  0.208055063
#&gt; 177 -0.1441292930  0.978743371 -0.107085073
#&gt; 178 -0.1564546371  0.225198808  0.361694675
#&gt; 179 -0.0301234812 -0.964846872  0.859330830
#&gt; 180 -0.0788320840  0.964138468 -0.178279418
#&gt; 181  0.1547533802  0.180212406 -0.955025187
#&gt; 182  0.0134141423 -0.938097088  0.685544413
#&gt; 183 -0.1466138383 -0.497813159  0.643134156
#&gt; 184  0.0750661667  0.364500900 -0.664857331
#&gt; 185  0.2729540631 -0.408515880 -0.834756025
#&gt; 186 -0.0094790928  0.952382641 -0.584445609
#&gt; 187 -0.1891560792  0.934576210 -0.091672360
#&gt; 188 -0.2789793740  0.917442349  0.184754662
#&gt; 189 -0.0406207051 -0.931485629  0.847430594
#&gt; 190  0.2601446593 -0.366912988 -0.974388276
#&gt; 191 -0.1376258024  0.684010640  0.003131385
#&gt; 192 -0.1521770282 -0.168863559  0.617068440
#&gt; 193  0.1503111507  0.248373198 -0.929363417
#&gt; 194 -0.0873568736  1.145242165 -1.101278951
#&gt; 195 -0.0891273823 -0.712918227  0.721165439
#&gt; 196 -0.2667160991  0.546688525  0.399290715
#&gt; 197  0.1071643047  0.223306142 -0.935105537
#&gt; 198  0.0302671962 -0.909519985  0.581304365
#&gt; 199  0.1990217466 -0.497637448 -0.503009968
#&gt; 200  0.0957981632  0.321454472 -0.443307026
#&gt; 201 -0.0014062149 -0.845024222  0.818363637
#&gt; 202  0.1344591851  0.559330974 -1.231737645
#&gt; 203  0.1623875515 -0.761280930  0.118166489
#&gt; 204  0.0107416230 -0.219164999  0.308415815
#&gt; 205 -0.2324829353  0.657981202  0.192666697
#&gt; 206 -0.0196753757  1.250503744 -1.202528881
#&gt; 207  0.0127394126 -0.022162455  0.151963494
#&gt; 208 -0.0014658088  0.452037570 -0.157623988
#&gt; 209  0.0638494259  0.762679423 -1.024376036
#&gt; 210 -0.2436754233  0.499151544  0.410517152
#&gt; 211  0.0148389797 -0.065068488  0.073089143
#&gt; 212 -0.1149849869 -0.611351584  0.782729760
#&gt; 213  0.1203822435  0.435577411 -1.022616795
#&gt; 214  0.1746306421  0.333934407 -1.042340031
#&gt; 215  0.0009646651  1.192985385 -1.203410555
#&gt; 216  0.1313480886  0.132995398 -0.905914061
#&gt; 217  0.2485523283 -0.744206066  0.112308618
#&gt; 218 -0.1144357263 -0.684861683  0.654593231
#&gt; 219 -0.1606748779  0.556311156  0.101461008
#&gt; 220 -0.0745065735 -0.724341318  0.867782786
#&gt; 221 -0.2893707046  0.840277641  0.481969880
#&gt; 222 -0.0412884405 -0.871574080  0.860790640
#&gt; 223 -0.2560325073  0.845346544  0.394488327
#&gt; 224  0.1682057770 -0.670672226 -0.072101407
#&gt; 225  0.1183584000 -0.938795461  0.609599662
#&gt; 226 -0.0180504854  1.127162531 -1.216914223
#&gt; 227 -0.2986153069  0.857128765  0.447934014
#&gt; 228 -0.0138619847 -0.930371123  0.835404850
#&gt; 229  0.2741169940 -0.412521683 -0.895299640
#&gt; 230  0.0229067363  0.065464758 -0.037335073
#&gt; 231  0.2112389661 -0.208450721 -0.780234296
#&gt; 232  0.0765627983  0.853575168 -1.195316793
#&gt; 233  0.0364691961  0.077988015 -0.072389708
#&gt; 234 -0.0221849295 -0.871167280  0.663937018
#&gt; 235  0.0782283559  0.057983277 -0.196911297
#&gt; 236 -0.2036662751  0.732655970  0.068013937
#&gt; 237  0.0639073385  0.387662082 -0.793925517
#&gt; 238 -0.0828419918  0.919046194 -0.263369690
#&gt; 239 -0.2902813823  0.871784777  0.431371603
#&gt; 240 -0.1232579583 -0.649555303  0.812864472
#&gt; 241 -0.0980349748  0.718203898 -0.169016707
#&gt; 242 -0.0371500792 -0.972240136  0.740093604
#&gt; 243 -0.2560642991  0.815035966  0.524905732
#&gt; 244  0.1131851280  0.076624663 -0.269489092
#&gt; 245 -0.0998088790 -0.844491236  0.843877725
#&gt; 246 -0.1119790468 -0.655343779  0.643000925
#&gt; 247  0.0477732237  0.075485928 -0.118505802
#&gt; 248  0.0222124462  0.832350658 -0.896091660
#&gt; 249 -0.0112522808  1.219631014 -1.237556232
#&gt; 250 -0.2022397684  0.790583599  0.254245763</div><div class='input'>
<span class='co'># Policy learning</span>
<span class='kw'>Gamma.matrix</span> <span class='op'>&lt;-</span> <span class='fu'><a href='double_robust_scores.causal_forest.html'>double_robust_scores</a></span>(<span class='kw'>multi.forest</span>)

<span class='kw'>train</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/sample.html'>sample</a></span>(<span class='fl'>1</span><span class='op'>:</span><span class='kw'>n</span>, <span class='fl'>200</span>)
<span class='kw'>opt.tree</span> <span class='op'>&lt;-</span> <span class='fu'><a href='policy_tree.html'>policy_tree</a></span>(<span class='kw'>X</span>[<span class='kw'>train</span>, ], <span class='kw'>Gamma.matrix</span>[<span class='kw'>train</span>, ], depth = <span class='fl'>2</span>)
<span class='kw'>opt.tree</span>
</div><div class='output co'>#&gt; policy_tree object 
#&gt; Tree depth:  2 
#&gt; Actions:  1: A 2: B 3: C 
#&gt; Variable splits: 
#&gt; (1) split_variable: X3  split_value: 0.21745 
#&gt;   (2) split_variable: X2  split_value: -0.241997 
#&gt;     (4) * action: 1 
#&gt;     (5) * action: 2 
#&gt;   (3) split_variable: X1  split_value: 1.61232 
#&gt;     (6) * action: 3 
#&gt;     (7) * action: 1 </div><div class='input'>
<span class='co'># Predict treatment on held out data</span>
<span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='kw'>opt.tree</span>, <span class='kw'>X</span>[<span class='op'>-</span><span class='kw'>train</span>, ])
</div><div class='output co'>#&gt;  [1] 2 3 1 3 1 3 2 1 1 2 2 3 3 2 1 3 2 1 3 3 2 2 3 2 3 1 3 2 2 3 3 3 3 3 1 2 1 2
#&gt; [39] 2 2 2 1 3 1 3 2 2 1 3 2</div><div class='input'><span class='co'># }</span>

</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Zhengyuan Zhou, Susan Athey, Stefan Wager, Ayush Kanodia, Erik Sverdrup.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


