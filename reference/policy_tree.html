<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>Fit a policy with exact tree search — policy_tree • policytree</title>

<!-- favicons -->
<link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png" />
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png" />
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png" />
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png" />

<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>



  
  <script src="../extra.js"></script>

<meta property="og:title" content="Fit a policy with exact tree search — policy_tree" />
<meta property="og:description" content="Finds the optimal (maximizing the sum of rewards) depth L tree by exhaustive search. If the optimal
action is the same in both the left and right leaf of a node, the node is pruned." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">policytree</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.3</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../articles/policytree.html">Get started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li>
  <a href="../CHANGELOG.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/grf-labs/policytree">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>Fit a policy with exact tree search</h1>
    <small class="dont-index">Source: <a href='https://github.com/grf-labs/policytree/blob/master/R/policy_tree.R'><code>R/policy_tree.R</code></a></small>
    <div class="hidden name"><code>policy_tree.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>Finds the optimal (maximizing the sum of rewards) depth L tree by exhaustive search. If the optimal
action is the same in both the left and right leaf of a node, the node is pruned.</p>
    </div>

    <pre class="usage"><span class='fu'>policy_tree</span>(<span class='kw'>X</span>, <span class='kw'>Gamma</span>, depth = <span class='fl'>2</span>, split.step = <span class='fl'>1</span>)</pre>

    <h2 class="hasAnchor" id="arguments"><a class="anchor" href="#arguments"></a>Arguments</h2>
    <table class="ref-arguments">
    <colgroup><col class="name" /><col class="desc" /></colgroup>
    <tr>
      <th>X</th>
      <td><p>The covariates used. Dimension \(Np\) where \(p\) is the number of features.</p></td>
    </tr>
    <tr>
      <th>Gamma</th>
      <td><p>The rewards for each action. Dimension \(Nd\) where \(d\) is the number of actions.</p></td>
    </tr>
    <tr>
      <th>depth</th>
      <td><p>The depth of the fitted tree. Default is 2.</p></td>
    </tr>
    <tr>
      <th>split.step</th>
      <td><p>An optional approximation parameter (integer above zero), the number of possible splits
to consider when performing tree search. split.step = 1 (default) considers every possible split, split.step = 10
considers splitting at every 10'th distinct value and will yield a substantial speedup for densely packed
continuous data.</p></td>
    </tr>
    </table>

    <h2 class="hasAnchor" id="value"><a class="anchor" href="#value"></a>Value</h2>

    <p>A policy_tree object.</p>
    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>The amortized runtime of the exact tree search is \(O(p^k n^k (log n + d) + pnlog n)\) where p is the number of features, d the number of treatments, n the number of observations, and \(k \geq 1\) the tree depth.</p>
<p>For a depth two tree this is \(O(p^2 n^2 (log n + d))\) (ignoring the last term which is a global sort done at the beginning) meaning that it scales quadratically with the number of observations, i.e. if you double the number of observations, the search will take at least four times as long.</p>
<p>For a depth three tree it is \(O(p^3 n^3 (log n + d))\). If a depth two tree with 1000 observations, 4 features and 3 actions took around t seconds, you can expect the level three tree to take approximately \(1000\cdot 4\) times as long (\(\approx\frac{p^3n^2}{p^2n^2}=pn\))</p>
<p>The runtime above is with continuous features. There are considerable time savings when the features are
discrete. In the extreme case with all binary observations, the runtime will be practically linear in n.</p>
<p>The optional approximation parameter <code>split.step</code> emulates rounding the data and is recommended to experiment with in order to reduce the runtime.</p>
    <h2 class="hasAnchor" id="references"><a class="anchor" href="#references"></a>References</h2>

    <p>Sverdrup, Erik, Ayush Kanodia, Zhengyuan Zhou, Susan Athey, and Stefan Wager.
"policytree: Policy learning via doubly robust empirical welfare maximization over trees."
Journal of Open Source Software 5, no. 50 (2020): 2232.</p>
<p>Zhou, Zhengyuan, Susan Athey, and Stefan Wager. "Offline multi-action policy learning:
Generalization and optimization." arXiv preprint arXiv:1810.04778 (2018).</p>

    <h2 class="hasAnchor" id="examples"><a class="anchor" href="#examples"></a>Examples</h2>
    <pre class="examples"><div class='input'><span class='co'># \donttest{</span>
<span class='co'># Fit a depth two tree on doubly robust treatment effect estimates</span>
<span class='co'># from a causal forest.</span>
<span class='kw'>n</span> <span class='op'>&lt;-</span> <span class='fl'>10000</span>
<span class='kw'>p</span> <span class='op'>&lt;-</span> <span class='fl'>5</span>
<span class='kw'>X</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/base/Round.html'>round</a></span>(<span class='fu'><a href='https://rdrr.io/r/base/matrix.html'>matrix</a></span>(<span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>rnorm</a></span>(<span class='kw'>n</span> <span class='op'>*</span> <span class='kw'>p</span>), <span class='kw'>n</span>, <span class='kw'>p</span>), <span class='fl'>2</span>)
<span class='kw'>W</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/Binomial.html'>rbinom</a></span>(<span class='kw'>n</span>, <span class='fl'>1</span>, <span class='fl'>1</span> <span class='op'>/</span> (<span class='fl'>1</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span>(<span class='kw'>X</span>[, <span class='fl'>3</span>])))
<span class='kw'>tau</span> <span class='op'>&lt;-</span> <span class='fl'>1</span> <span class='op'>/</span> (<span class='fl'>1</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/base/Log.html'>exp</a></span>((<span class='kw'>X</span>[, <span class='fl'>1</span>] <span class='op'>+</span> <span class='kw'>X</span>[, <span class='fl'>2</span>]) <span class='op'>/</span> <span class='fl'>2</span>)) <span class='op'>-</span> <span class='fl'>0.5</span>
<span class='kw'>Y</span> <span class='op'>&lt;-</span> <span class='kw'>X</span>[, <span class='fl'>3</span>] <span class='op'>+</span> <span class='kw'>W</span> <span class='op'>*</span> <span class='kw'>tau</span> <span class='op'>+</span> <span class='fu'><a href='https://rdrr.io/r/stats/Normal.html'>rnorm</a></span>(<span class='kw'>n</span>)
<span class='kw'>c.forest</span> <span class='op'>&lt;-</span> <span class='kw'>grf</span>::<span class='fu'><a href='https://rdrr.io/pkg/grf/man/causal_forest.html'>causal_forest</a></span>(<span class='kw'>X</span>, <span class='kw'>Y</span>, <span class='kw'>W</span>)
<span class='kw'>dr.scores</span> <span class='op'>&lt;-</span> <span class='fu'><a href='double_robust_scores.causal_forest.html'>double_robust_scores</a></span>(<span class='kw'>c.forest</span>)

<span class='kw'>tree</span> <span class='op'>&lt;-</span> <span class='fu'>policy_tree</span>(<span class='kw'>X</span>, <span class='kw'>dr.scores</span>, <span class='fl'>2</span>)
<span class='kw'>tree</span>
</div><div class='output co'>#&gt; policy_tree object 
#&gt; Tree depth:  2 
#&gt; Actions:  1: control 2: treated 
#&gt; Variable splits: 
#&gt; (1) split_variable: X3  split_value: 0.69 
#&gt;   (2) split_variable: X2  split_value: -0.27 
#&gt;     (4) * action: 2 
#&gt;     (5) * action: 1 
#&gt;   (3) split_variable: X1  split_value: 0.56 
#&gt;     (6) * action: 2 
#&gt;     (7) * action: 1 </div><div class='input'>
<span class='co'># Predict treatment assignment.</span>
<span class='kw'>predicted</span> <span class='op'>&lt;-</span> <span class='fu'><a href='https://rdrr.io/r/stats/predict.html'>predict</a></span>(<span class='kw'>tree</span>, <span class='kw'>X</span>)

<span class='fu'><a href='https://rdrr.io/r/graphics/plot.default.html'>plot</a></span>(<span class='kw'>X</span>[, <span class='fl'>1</span>], <span class='kw'>X</span>[, <span class='fl'>2</span>], col = <span class='kw'>predicted</span>)
</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/legend.html'>legend</a></span>(<span class='st'>"topright"</span>, <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='st'>"control"</span>, <span class='st'>"treat"</span>), col = <span class='fu'><a href='https://rdrr.io/r/base/c.html'>c</a></span>(<span class='fl'>1</span>, <span class='fl'>2</span>), pch = <span class='fl'>19</span>)
</div><div class='input'><span class='fu'><a href='https://rdrr.io/r/graphics/abline.html'>abline</a></span>(<span class='fl'>0</span>, <span class='op'>-</span><span class='fl'>1</span>, lty = <span class='fl'>2</span>)
</div><div class='img'><img src='policy_tree-1.png' alt='' width='700' height='433' /></div><div class='input'><span class='co'># }</span>
</div></pre>
  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Zhengyuan Zhou, Susan Athey, Stefan Wager, Ayush Kanodia, Erik Sverdrup.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


